{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import io"
      ],
      "metadata": {
        "id": "GHE5i5FQjW36"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Automatically get the correct filename, no matter what it's called\n",
        "filename = next(iter(uploaded))\n",
        "print(f\"Using file: {filename}\")\n",
        "\n",
        "# Read the uploaded CSV file\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "pgvFbLffbZx5",
        "outputId": "ac23cd26-60f0-4cb2-ec5a-0d2b4be972d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6b32286-cd56-441f-82cb-f38cdd18d8df\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d6b32286-cd56-441f-82cb-f38cdd18d8df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train.csv\n",
            "Using file: train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Alley\"] = df[\"Alley\"].replace(np.nan, \"none\") # Remplacé les NaN par none\n",
        "df[\"Alley\"].value_counts() # to count the number of occurrences of each value in the \"Street\" column\n",
        "\n",
        "# si vous regardez dans la partie # BINARY VARIABLES, vous verez que les 0.0 ont un count de 1369, qui représente les none ici.\n",
        "# Les 1.0 représentent le Grvl.\n",
        "#Le Pave n'est pas représenté"
      ],
      "metadata": {
        "id": "TJcJQ0figimE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEPARATE EACH DATA TYPE AS TO TREAT THEM DIFFERENTLY\n",
        "\n",
        "n_unique = df.nunique() # compute nmbr of unique values for each col of df,\n",
        "# determines if data is binary or categorical\n",
        "dtypes = df.dtypes # retrieves data type for each col in df\n",
        "\n",
        "quant_threshold = 10 # threshold after which the data is considered quantitative\n",
        "\n",
        "# var where is col name will be stocked\n",
        "quant_var = []\n",
        "binary_var = []\n",
        "categorical_var = []\n",
        "\n",
        "\n",
        "for col in df.columns:\n",
        "  if dtypes[col] in ['int64', 'float64']:\n",
        "    if n_unique[col] == 2:\n",
        "      binary_var.append(col) # if col dt is numbers and has only two possible values\n",
        "\n",
        "    elif n_unique[col]>quant_threshold:\n",
        "      quant_var.append(col) # if col dt is numbers but has more than 10\n",
        "    else:\n",
        "      categorical_var.append(col)\n",
        "\n",
        "  elif dtypes[col] in ['object', 'category', 'bool']:\n",
        "        if n_unique[col] == 2:\n",
        "            if df[col].dtype == 'object':\n",
        "                # if the column is an object type but only has two values, convert it to binary\n",
        "                df[col] = df[col].map({df[col].unique()[0]: 0, df[col].unique()[1]: 1})\n",
        "            binary_var.append(col)\n",
        "        else:\n",
        "            categorical_var.append(col)\n",
        "\n",
        "df_quant = df[quant_var] # Quantitative variables\n",
        "df_binary = df[binary_var] # Binary variables\n",
        "df_categorical = df[categorical_var] # Categorical variables\n",
        "\n",
        "print(\"Quantitative variables:\", quant_var)\n",
        "print(\"Binary variables:\", binary_var)\n",
        "print(\"Categorical variables:\", categorical_var)\n",
        "\n",
        "# check that all our variables are here\n",
        "print(len(quant_var) + len(binary_var) + len(categorical_var))\n"
      ],
      "metadata": {
        "id": "3AOkdmQ8fvnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUANTITATIVE VARIABLES\n",
        "\n",
        "# Descriptive analysis: mean, sd, Conf interval etc\n",
        "def descriptive_stats(df_quand):\n",
        "  stats_summary = df_quant.describe().T #summary for each variable\n",
        "\n",
        "  for col in df_quant.columns:\n",
        "    mean = df_quant[col].mean()\n",
        "    sd = df_quant[col].std()\n",
        "    n = df_quant[col].count()\n",
        "    CI = stats.t.interval(0.95, n-1, loc = mean, scale= sd/np.sqrt(n))\n",
        "\n",
        "    stats_summary.loc[col, \"CI_95%_lower\"] = CI[0]\n",
        "    stats_summary.loc[col, \"CI_95%_upper\"] = CI[1]\n",
        "\n",
        "  return stats_summary\n",
        "\n",
        "stats_summary = descriptive_stats(df_quant)\n",
        "# print(stats_summary)\n",
        "\n",
        "# Correlation test with house prices\n",
        "\n",
        "def hypothesis_test(def_quant, price):\n",
        "  res = {}\n",
        "\n",
        "  for col in df_quant.columns:\n",
        "    if col == price:\n",
        "      continue\n",
        "\n",
        "\n",
        "    corr, p_value = pearsonr(df_quant[col], df_quant[price])\n",
        "    res[col] = {\"Correlation coeff\" : corr, \"P-value\": p_value}\n",
        "\n",
        "  return res\n",
        "\n",
        "print(hypothesis_test(df_quant, \"SalePrice\"))\n",
        "\n",
        "# Anova doesn't apply because its requires one quantitative and several categorical variables"
      ],
      "metadata": {
        "id": "NNcXVDqmkaiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I did this with chatgpt because i really didn't know how i could rank all these values\n",
        "def rank_features(df_quant, target_variable):\n",
        "    stats_summary = descriptive_stats(df_quant)\n",
        "    hypothesis_results = hypothesis_test(df_quant, target_variable)\n",
        "\n",
        "    # Convert hypothesis test results to Df for easier manipulation\n",
        "    hypothesis_df = pd.DataFrame(hypothesis_results).T\n",
        "\n",
        "    # Combine both descriptive stats and hypothesis test results into one DataFrame\n",
        "    combined_df = stats_summary.join(hypothesis_df)\n",
        "    # We will rank by correlation, p-value, and the variance\n",
        "\n",
        "    # Rank by correlation coefficient (absolute value to consider positive and negative correlations)\n",
        "    combined_df['abs_corr'] = combined_df['Correlation coeff'].abs()\n",
        "\n",
        "    # Add a score based on p-value (lower p-value = higher significance)\n",
        "    combined_df['p_value_rank'] = combined_df['P-value'].rank(ascending=True, method='min')\n",
        "\n",
        "    # Add a score based on the variance (higher variance = more spread = more informative)\n",
        "    combined_df['variance'] = combined_df['std'].rank(ascending=False, method='min')\n",
        "\n",
        "    # Final rank score (each factor is kind of arbirtarily weighted, the more * the more important it is considered)\n",
        "    combined_df['final_rank'] = combined_df['abs_corr'] * 10 + combined_df['p_value_rank'] * 2 + combined_df['variance'] * 5\n",
        "\n",
        "    combined_df_sorted = combined_df.sort_values(by='final_rank', ascending=False)\n",
        "\n",
        "    return combined_df_sorted[['Correlation coeff', 'P-value', 'CI_95%_lower', 'CI_95%_upper', 'variance', 'final_rank']]\n",
        "\n",
        "# Example usage (assuming df_quant is your quantitative DataFrame and \"SalePrice\" is the target variable)\n",
        "ranked_features = rank_features(df_quant, \"SalePrice\")\n",
        "print(ranked_features)"
      ],
      "metadata": {
        "id": "isMuJ9PQzW8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14786cf6-b674-4a70-82f9-7947c03ea055"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Correlation coeff        P-value   CI_95%_lower   CI_95%_upper  \\\n",
            "MoSold                  0.046432   7.612758e-02       6.183121       6.460714   \n",
            "TotRmsAbvGrd            0.533723  2.772281e-108       6.434365       6.601251   \n",
            "3SsnPorch               0.044584   8.858170e-02       1.904520       4.914658   \n",
            "YearRemodAdd            0.507101   3.164948e-96    1983.805876    1985.925631   \n",
            "LowQualFinSF           -0.025606   3.282073e-01       3.348348       8.340693   \n",
            "MSSubClass             -0.084284   1.266472e-03      54.725668      59.068853   \n",
            "YearBuilt               0.522897  2.990229e-103    1969.717276    1972.818340   \n",
            "ScreenPorch             0.111447   1.972140e-05      12.198530      17.923388   \n",
            "EnclosedPorch          -0.128578   8.255770e-07      18.816424      25.091795   \n",
            "BsmtFinSF2             -0.011378   6.639987e-01      38.267637      54.830993   \n",
            "OpenPorchSF             0.315856   3.493374e-35      43.258876      50.061672   \n",
            "WoodDeckSF              0.324413   3.972217e-37      87.809979     100.679062   \n",
            "Id                     -0.021917   4.026938e-01     708.855727     752.144273   \n",
            "GarageArea              0.623431  5.265038e-158     462.003997     483.956277   \n",
            "1stFlrSF                0.605852  5.394711e-147    1142.780384    1182.473040   \n",
            "2ndFlrSF                0.319334   5.764335e-36     324.582323     369.402609   \n",
            "MiscVal                -0.021190   4.184863e-01      18.019479      68.958603   \n",
            "BsmtUnfSF               0.214479   1.182976e-16     544.556203     589.924619   \n",
            "TotalBsmtSF             0.613581  9.484229e-152    1034.907554    1079.951351   \n",
            "BsmtFinSF1              0.386420   3.394110e-53     420.224932     467.054520   \n",
            "LotArea                 0.263843   1.123139e-24   10004.417990   11029.238175   \n",
            "GrLivArea               0.708624  4.518034e-223    1488.487012    1542.440385   \n",
            "LotFrontage                  NaN            NaN      68.675130      71.424787   \n",
            "MasVnrArea                   NaN            NaN      94.364217     113.006307   \n",
            "GarageYrBlt                  NaN            NaN    1977.201905    1979.810423   \n",
            "SalePrice                    NaN            NaN  176842.841041  184999.550740   \n",
            "\n",
            "               variance  final_rank  \n",
            "MoSold             25.0  159.464322  \n",
            "TotRmsAbvGrd       26.0  145.337232  \n",
            "3SsnPorch          21.0  141.445837  \n",
            "YearRemodAdd       24.0  139.071010  \n",
            "LowQualFinSF       18.0  128.256061  \n",
            "MSSubClass         19.0  127.842841  \n",
            "YearBuilt          20.0  117.228973  \n",
            "ScreenPorch        17.0  116.114466  \n",
            "EnclosedPorch      16.0  109.285780  \n",
            "BsmtFinSF2         13.0  109.113781  \n",
            "OpenPorchSF        15.0  100.158562  \n",
            "WoodDeckSF         14.0   91.244134  \n",
            "Id                  9.0   85.219167  \n",
            "GarageArea         11.0   65.234314  \n",
            "1stFlrSF           10.0   64.058522  \n",
            "2ndFlrSF            8.0   63.193338  \n",
            "MiscVal             4.0   62.211896  \n",
            "BsmtUnfSF           6.0   58.144791  \n",
            "TotalBsmtSF         7.0   47.135806  \n",
            "BsmtFinSF1          5.0   44.864198  \n",
            "LotArea             2.0   36.638434  \n",
            "GrLivArea           3.0   24.086245  \n",
            "LotFrontage        23.0         NaN  \n",
            "MasVnrArea         12.0         NaN  \n",
            "GarageYrBlt        22.0         NaN  \n",
            "SalePrice           1.0         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BINARY VARIABLES\n",
        "# Methods to be applied: descriptive stats, 2^k/fractional factorial design\n",
        "# print(df_binary)\n",
        "\n",
        "# REGARDER LE BOUT DE CODE APRES LES IMPORT & LE UPLOAD DU FICHIER\n",
        "\n",
        "Alley_count = df_binary['Alley'].value_counts() # ici y a au total 1419 valeur\n",
        "# alley a 3 valeurs et pas 2 (Grvl, Pave, NA). C'est pour ça qu'il y a des valeurs manquantes\n",
        "\n",
        "CentralAir_count = df_binary['CentralAir'].value_counts() # alors qu'ici y en a 1460\n",
        "Utilities_count = df_binary['Utilities'].value_counts() # 1460\n",
        "Street_count = df_binary['Street'].value_counts() #1460\n",
        "\n",
        "print(Alley_count, '\\n')\n",
        "print(CentralAir_count, '\\n')\n",
        "print(Utilities_count, '\\n')\n",
        "print(Street_count)\n"
      ],
      "metadata": {
        "id": "fRz8I-ZunsDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "a6a1602b-ea05-4445-fb46-40ea1900c731"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Alley'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Alley'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-45194dabc72f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# REGARDER LE BOUT DE CODE APRES LES IMPORT & LE UPLOAD DU FICHIER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mAlley_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_binary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Alley'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ici y a au total 1419 valeur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# alley a 3 valeurs et pas 2 (Grvl, Pave, NA). C'est pour ça qu'il y a des valeurs manquantes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Alley'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.hist(df_categorical[\"MSZoning\"]) # Je vais essayer de faire en sorte de mettre ça dans la for loop et avoir un histogram par value"
      ],
      "metadata": {
        "id": "PSRVfS6PiFSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CATEGORICAL VARIABLES\n",
        "# Methods to be applied: descritive, inference, 2^k/fractional factorial, anova\n",
        "# print(df_categorical)\n",
        "\n",
        "for i in df_categorical.columns:\n",
        "  print(df_categorical[i].value_counts(), '\\n')\n",
        "\n",
        "# Methods to use\n",
        "# 2^k, anova and descriptive stats"
      ],
      "metadata": {
        "id": "1OnKV7PIzY_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
